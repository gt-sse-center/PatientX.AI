{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6acf4b753ba73fa3",
   "metadata": {},
   "source": [
    "# BERTopic\n",
    "Using BERTopic to identify topics in dementia forum text. Each iteration adds a new level to the model. BERTopic has multiple fully customizable steps to it and each iteration explores with different parts of the model's pipeline\n",
    "\n",
    "![BERTopic Structure](files/bertopic-structure.png \"BERTopic Structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f17e585d36ed5",
   "metadata": {},
   "source": [
    "## Data Setup\n",
    "Read data into a list where each document is an item in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbbb3f496cb603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read documents from the file\n",
    "# corpus_threads_combined.txt contains all dementia forum data\n",
    "# Each thread in the forum is represented as a document and separated by a new line\n",
    "\n",
    "with open('../data/corpus_threads_combined.txt', 'r', encoding='utf-8') as file:\n",
    "    documents = file.read().split('\\n')  # Split on newline to get individual documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5fbd85cce2e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the following packages, depending on your system, you could use regular pip\n",
    "!pip3 install bertopic\n",
    "!pip3 install spacy\n",
    "!pip3 install datamapplot\n",
    "!pip3 install \"nbformat>=4.2.0\"\n",
    "!pip3 install --upgrade nbformat\n",
    "!pip3 install ipykernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c6d02f49cd27f",
   "metadata": {},
   "source": [
    "## Approach 1: \n",
    "- **Embedding Model:** [all-MiniLM-L6-v2 Sentence Transformer](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "- **Dimensionality Reduction:** UMAP\n",
    "- **Clustering:** HDBScan\n",
    "- **Tokenizer:** *None*\n",
    "- **Weighting Scheme:** *None*\n",
    "- **Representation Tuning:** *None*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed227d04eaeea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize a sentence transformer model for embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create a BERTopic model\n",
    "topic_model = BERTopic(embedding_model=embedding_model, verbose=True)\n",
    "\n",
    "# Fit the model on the documents\n",
    "topics, probs = topic_model.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de98bfff7d5a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results and inter-topic distance map visualization\n",
    "print(topic_model.get_topic_info())\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713008a010b293ae",
   "metadata": {},
   "source": [
    "## Approach 2: additional stop word removal\n",
    "- **Embedding Model:** [all-MiniLM-L6-v2 Sentence Transformer](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "- **Dimensionality Reduction:** UMAP\n",
    "- **Clustering:** HDBScan\n",
    "- **Tokenizer:** CountVectorizer\n",
    "- **Weighting Scheme:** *None*\n",
    "- **Representation Tuning:** *None*\n",
    "### Clean up data\n",
    "Remove some custom stop words not in the existing spacy model's English stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11755848b38c073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove custom stop words that aren't caught by spacy's model\n",
    "from spacy.lang.en import stop_words\n",
    "\n",
    "stop_words = list(stop_words.STOP_WORDS)\n",
    "custom_stop_words = ['with', 'my', 'your', 'she', 'this', 'was', 'her', 'have', 'as', 'he', 'him', 'but', 'not', 'so', 'are', 'at', 'be', 'has', 'do', 'got', 'how', 'on', 'or', 'would', 'will', 'what', 'they', 'if', 'or', 'get', 'can', 'we', 'me', 'can', 'has', 'his', 'there', 'them', 'just', 'am', 'by', 'that', 'from', 'it', 'is', 'in', 'you', 'also', 'very', 'had', 'a', 'an', 'for']\n",
    "\n",
    "stop_words += custom_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ec5d2ac8741c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=custom_stop_words)\n",
    "topic_model_2 = BERTopic(vectorizer_model=vectorizer_model, embedding_model=embedding_model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a1c8b5e0c2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the BERTopic model to the documents\n",
    "topics_2, probs_2 = topic_model_2.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eadc8ecb660be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the topic information\n",
    "print(topic_model_2.get_topic_info())\n",
    "\n",
    "# visualize inter-topic distance map\n",
    "topic_model_2.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c6ecc23ab467a",
   "metadata": {},
   "source": [
    "## Approach 3: c-TF-IDF weighting scheme\n",
    "- **Embedding Model:** [all-MiniLM-L6-v2 Sentence Transformer](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "- **Dimensionality Reduction:** UMAP\n",
    "- **Clustering:** HDBScan\n",
    "- **Tokenizer:** CountVectorizer\n",
    "- **Weighting Scheme:** c-TF-IDF Transformer\n",
    "- **Representation Tuning:** *none*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13ad8cf1651e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "topic_model_3 = BERTopic(ctfidf_model=ctfidf_model, embedding_model=embedding_model, verbose=True, min_topic_size=100, vectorizer_model=vectorizer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fca7045b1ef800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the BERTopic model to the documents\n",
    "topics_3, probs_3 = topic_model_3.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a858cc4f383f5cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the topic information\n",
    "print(topic_model_3.get_topic_info())\n",
    "\n",
    "# visualize inter-topic distance map\n",
    "topic_model_3.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95406de44b3f9f21",
   "metadata": {},
   "source": [
    "## Approach 4: updated embedding model\n",
    "- **Embedding Model:** [pritamdeka/S-PubMedBert-MS-MARCO](https://huggingface.co/pritamdeka/S-PubMedBert-MS-MARCO)\n",
    "- **Dimensionality Reduction:** UMAP\n",
    "- **Clustering:** HDBScan\n",
    "- **Tokenizer:** CountVectorizer\n",
    "- **Weighting Scheme:** c-TF-IDF\n",
    "- **Representation Tuning:** *none*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67871ad3558689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERTopic with a sentence transformer fine-tuned on medical text for embeddings\n",
    "medical_embedding_model = SentenceTransformer('pritamdeka/S-PubMedBert-MS-MARCO')\n",
    "\n",
    "# Note: we tried using the embedding model below but came out with far worse results than the embedding model above\n",
    "# nvidia_embedding_model = SentenceTransformer('dunzhang/stella_en_1.5B_v5')\n",
    "\n",
    "topic_model_4 = BERTopic(ctfidf_model=ctfidf_model, embedding_model=medical_embedding_model, verbose=True, min_topic_size=100, vectorizer_model=vectorizer_model)\n",
    "\n",
    "# Fit the BERTopic model to the documents\n",
    "topics_4, probs_4 = topic_model_4.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6ea38b54394893",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datamapplot\n",
    "\n",
    "topic_model_4.visualize_document_datamap(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf71e417e46be5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the topic information\n",
    "print(topic_model_4.get_topic_info())\n",
    "\n",
    "# visualize inter-topic distance map\n",
    "topic_model_4.visualize_topics()\n",
    "\n",
    "# visualize hierarchy\n",
    "topic_model_4.visualize_hierarchy()\n",
    "\n",
    "# visualize topic word scores\n",
    "topic_model_4.visualize_barchart()\n",
    "\n",
    "# visualize term rank\n",
    "topic_model_4.visualize_term_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf6bd0fb2c55ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize with datamapplot\n",
    "topic_model_4.visualize_document_datamap(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9899025fb0a6e765",
   "metadata": {},
   "source": [
    "## Approach 5: adding KeyBERT representation model\n",
    "- **Embedding Model:** [pritamdeka/S-PubMedBert-MS-MARCO](https://huggingface.co/pritamdeka/S-PubMedBert-MS-MARCO)\n",
    "- **Dimensionality Reduction:** UMAP\n",
    "- **Clustering:** HDBScan\n",
    "- **Tokenizer:** CountVectorizer\n",
    "- **Weighting Scheme:** c-TF-IDF\n",
    "- **Representation Tuning:** KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195cac749a7374b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "# Create your representation model\n",
    "representation_model = KeyBERTInspired()\n",
    "\n",
    "topic_model_5 = BERTopic(ctfidf_model=ctfidf_model, embedding_model=medical_embedding_model, verbose=True, min_topic_size=100, vectorizer_model=vectorizer_model, representation_model=representation_model)\n",
    "\n",
    "\n",
    "# Fit the BERTopic model to the documents\n",
    "topics_5, probs_5 = topic_model_5.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6e4aa4ce896057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the topic information\n",
    "print(topic_model_5.get_topic_info())\n",
    "\n",
    "# visualize inter-topic distance map\n",
    "topic_model_5.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7360e1dc51e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERTopic with a sentence transformer for embeddings\n",
    "nvidia_embedding_model = SentenceTransformer('dunzhang/stella_en_1.5B_v5')\n",
    "topic_model_nvidia = BERTopic(ctfidf_model=ctfidf_model, embedding_model=nvidia_embedding_model, verbose=True, min_topic_size=100, vectorizer_model=vectorizer_model)\n",
    "\n",
    "\n",
    "# Fit the BERTopic model to the documents\n",
    "topics_nvidia, probs_nvidia = topic_model_nvidia.fit_transform(documents)\n",
    "\n",
    "# Print the topic information\n",
    "print(topic_model_nvidia.get_topic_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cee5f814fd067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_4.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d153a511ffab00c",
   "metadata": {},
   "source": [
    "## Approach 6: Add LLM representation\n",
    "- **Embedding Model:** [pritamdeka/S-PubMedBert-MS-MARCO](https://huggingface.co/pritamdeka/S-PubMedBert-MS-MARCO)\n",
    "- **Dimensionality Reduction:** UMAP\n",
    "- **Clustering:** HDBScan\n",
    "- **Tokenizer:** CountVectorizer\n",
    "- **Weighting Scheme:** c-TF-IDF\n",
    "- **Representation Model:** [mistral-small](https://ollama.com/library/mistral-small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36977f3d65454a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from MistralRepresentation import MistralRepresentation\n",
    "\n",
    "representation_model = MistralRepresentation() \n",
    "topic_model_mistral = BERTopic(ctfidf_model=ctfidf_model, embedding_model=medical_embedding_model, verbose=True, min_topic_size=100, vectorizer_model=vectorizer_model, representation_model=representation_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849b444fce6d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_mistral.fit_transform(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535526ba62d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output representations to CSV and markdown\n",
    "print(topic_model_mistral.get_topic_info())\n",
    "# this will save the output to a CSV file, increment the file number each time to help track the updated output\n",
    "file_number = 1\n",
    "topic_model_mistral.get_topic_info()['Representation'].to_csv('mistral_output_prompt_optimized_' + str(file_number) + '.csv')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def format_topic_info_to_markdown(topic_info):\n",
    "    markdown_content = \"\"\n",
    "    for index, row in topic_info.iterrows():\n",
    "        topic_id = row['Topic']\n",
    "        topic_name = row['Name']\n",
    "        markdown_content += f\"## Topic {topic_id}\\n\\n\"\n",
    "        markdown_content += f\"{topic_name}\\n\\n\"\n",
    "    return markdown_content\n",
    "\n",
    "def write_to_markdown(markdown_content, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(markdown_content)\n",
    "\n",
    "topic_info = topic_model_mistral.get_topic_info()\n",
    "\n",
    "# Format the topic information and write to a Markdown file\n",
    "markdown_content = format_topic_info_to_markdown(topic_info)\n",
    "write_to_markdown(markdown_content, 'mistral_output_prompt_optimized_' + str(file_number) + '.md')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patientx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
