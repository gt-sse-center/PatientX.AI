{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# BERTopic\n",
    "Using BERTopic to identify topics in dementia forum text"
   ],
   "id": "6acf4b753ba73fa3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Setup\n",
    "Read data into a list where each document is an item in the list"
   ],
   "id": "a73f17e585d36ed5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Read documents from the file\n",
    "# corpus_threads_combined.txt contains all dementia forum data\n",
    "# Each thread in the forum is represented as a document and separated by a new line\n",
    "\n",
    "with open('../data/corpus_threads_combined.txt', 'r', encoding='utf-8') as file:\n",
    "    documents = file.read().split('\\n')  # Split on newline to get individual documents"
   ],
   "id": "4edbbb3f496cb603"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# install bertopic\n",
    "\n",
    "!pip install bertopic"
   ],
   "id": "7f5fbd85cce2e908"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Approach 1: \n",
    "- **Embedding Model:** [all-MiniLM-L6-v2 Sentence Transformer](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "- **Dimensionality Reduction:** UMAP\n",
    "- **Clustering:** HDBScan\n",
    "- **Tokenizer:** *None*\n",
    "- **Weighting Scheme:** c-TF-IDF\n",
    "- **Representation Tuning:** *none*"
   ],
   "id": "161c6d02f49cd27f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize a sentence transformer model for embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create a BERTopic model\n",
    "topic_model = BERTopic(embedding_model=embedding_model, verbose=True)\n",
    "\n",
    "# Fit the model on the documents\n",
    "topics, probs = topic_model.fit_transform(documents)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Show results and intertopic distance map visualization\n",
    "print(topic_model.get_topic_info())\n",
    "topic_model.visualize_topics()"
   ],
   "id": "9de98bfff7d5a1d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Clean up data\n",
    "Remove some custom stop words"
   ],
   "id": "bd2d6fb70eb18dd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# remove custom stop words that aren't caught by spacy's model\n",
    "from spacy.lang.en import stop_words\n",
    "\n",
    "stop_words = list(stop_words.STOP_WORDS)\n",
    "custom_stop_words = ['with', 'my', 'your', 'she', 'this', 'was', 'her', 'have', 'as', 'he', 'him', 'but', 'not', 'so', 'are', 'at', 'be', 'has', 'do', 'got', 'how', 'on', 'or', 'would', 'will', 'what', 'they', 'if', 'or', 'get', 'can', 'we', 'me', 'can', 'has', 'his', 'there', 'them', 'just', 'am', 'by', 'that', 'from', 'it', 'is', 'in', 'you', 'also', 'very', 'had', 'a', 'an', 'for']\n",
    "\n",
    "stop_words += custom_stop_words"
   ],
   "id": "7ee1063c569b732c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Approach 2: \n",
    "- **Embedding Model:** [all-MiniLM-L6-v2 Sentence Transformer](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "- **Dimensionality Reduction:** UMAP\n",
    "- **Clustering:** HDBScan\n",
    "- **Tokenizer:** CountVectorizer\n",
    "- **Weighting Scheme:** c-TF-IDF\n",
    "- **Representation Tuning:** *none*"
   ],
   "id": "713008a010b293ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=custom_stop_words)\n",
    "topic_model_2 = BERTopic(vectorizer_model=vectorizer_model, embedding_model=embedding_model, verbose=True)"
   ],
   "id": "e05ec5d2ac8741c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
